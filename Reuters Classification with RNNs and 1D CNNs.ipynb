{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path='reuters.npz',\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n",
      "(8982,)\n",
      "(2246,)\n",
      "(2246,)\n",
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207]\n",
      "[ 3  4  3 ... 25  3 25]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train[0][0:10])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns lists of integers into a 2D integer tensor of shape (samples, maxlen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 100)\n",
      "(2246, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn labels to one-hot encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 46)\n",
      "(2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                204832    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 784,782\n",
      "Trainable params: 784,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "max_features = max(x_train.shape[0], x_test.shape[0])\n",
    "num_categories = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/15\n",
      "7185/7185 [==============================] - 2s 220us/step - loss: 1.9520 - acc: 0.4843 - val_loss: 1.6292 - val_acc: 0.5893\n",
      "Epoch 2/15\n",
      "7185/7185 [==============================] - 1s 164us/step - loss: 1.3692 - acc: 0.6564 - val_loss: 1.4164 - val_acc: 0.6550\n",
      "Epoch 3/15\n",
      "7185/7185 [==============================] - 1s 168us/step - loss: 0.9102 - acc: 0.7783 - val_loss: 1.3522 - val_acc: 0.6878\n",
      "Epoch 4/15\n",
      "7185/7185 [==============================] - 1s 162us/step - loss: 0.5889 - acc: 0.8632 - val_loss: 1.4478 - val_acc: 0.6856\n",
      "Epoch 5/15\n",
      "7185/7185 [==============================] - 1s 162us/step - loss: 0.3809 - acc: 0.9168 - val_loss: 1.5439 - val_acc: 0.6750\n",
      "Epoch 6/15\n",
      "7185/7185 [==============================] - 1s 161us/step - loss: 0.2543 - acc: 0.9460 - val_loss: 1.6756 - val_acc: 0.6700\n",
      "Epoch 7/15\n",
      "7185/7185 [==============================] - 1s 159us/step - loss: 0.1964 - acc: 0.9571 - val_loss: 1.7036 - val_acc: 0.6683\n",
      "Epoch 8/15\n",
      "7185/7185 [==============================] - 1s 160us/step - loss: 0.1723 - acc: 0.9588 - val_loss: 1.6875 - val_acc: 0.6761\n",
      "Epoch 9/15\n",
      "7185/7185 [==============================] - 1s 160us/step - loss: 0.1456 - acc: 0.9606 - val_loss: 1.8556 - val_acc: 0.6767\n",
      "Epoch 10/15\n",
      "7185/7185 [==============================] - 1s 161us/step - loss: 0.1339 - acc: 0.9616 - val_loss: 1.8006 - val_acc: 0.6739\n",
      "Epoch 11/15\n",
      "7185/7185 [==============================] - 1s 162us/step - loss: 0.1245 - acc: 0.9608 - val_loss: 1.8412 - val_acc: 0.6717\n",
      "Epoch 12/15\n",
      "7185/7185 [==============================] - 1s 160us/step - loss: 0.1177 - acc: 0.9628 - val_loss: 1.9098 - val_acc: 0.6644\n",
      "Epoch 13/15\n",
      "7185/7185 [==============================] - 1s 160us/step - loss: 0.1104 - acc: 0.9628 - val_loss: 2.0117 - val_acc: 0.6661\n",
      "Epoch 14/15\n",
      "7185/7185 [==============================] - 1s 160us/step - loss: 0.1063 - acc: 0.9613 - val_loss: 2.1055 - val_acc: 0.6572\n",
      "Epoch 15/15\n",
      "7185/7185 [==============================] - 1s 161us/step - loss: 0.1015 - acc: 0.9606 - val_loss: 2.0181 - val_acc: 0.6867\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Not much increase in validation accuracy after the 3-4 epoch, and the validation loss stops improving around then as well.\n",
    "- Starts overfitting around the 2nd epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 586,094\n",
      "Trainable params: 586,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 24s 3ms/step - loss: 2.4271 - acc: 0.3851 - val_loss: 2.0715 - val_acc: 0.4758\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 23s 3ms/step - loss: 1.9442 - acc: 0.4932 - val_loss: 1.9474 - val_acc: 0.4769\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 23s 3ms/step - loss: 1.6323 - acc: 0.5807 - val_loss: 1.8935 - val_acc: 0.4925\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 23s 3ms/step - loss: 1.3968 - acc: 0.6482 - val_loss: 1.8075 - val_acc: 0.5292\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 25s 3ms/step - loss: 1.1746 - acc: 0.7088 - val_loss: 1.8524 - val_acc: 0.5353\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 22s 3ms/step - loss: 0.9624 - acc: 0.7651 - val_loss: 1.8745 - val_acc: 0.5448\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 23s 3ms/step - loss: 0.7960 - acc: 0.8088 - val_loss: 1.9355 - val_acc: 0.5487\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 21s 3ms/step - loss: 0.6673 - acc: 0.8419 - val_loss: 2.0400 - val_acc: 0.5292\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 21s 3ms/step - loss: 0.5631 - acc: 0.8724 - val_loss: 2.1446 - val_acc: 0.5303\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 21s 3ms/step - loss: 0.4863 - acc: 0.8921 - val_loss: 2.2025 - val_acc: 0.5209\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Computationally expensive and performed worse than the simple Dense network\n",
    "- Validation loss stopped improving at around the 7th epoch\n",
    "- Starts overfitting around the 3rd epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 610,862\n",
      "Trainable params: 610,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 2.1743 - acc: 0.4288 - val_loss: 1.9566 - val_acc: 0.4775\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 53s 7ms/step - loss: 1.7618 - acc: 0.5272 - val_loss: 1.7151 - val_acc: 0.5281\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 53s 7ms/step - loss: 1.6227 - acc: 0.5585 - val_loss: 1.6056 - val_acc: 0.5765\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 1.5152 - acc: 0.5925 - val_loss: 1.5660 - val_acc: 0.5821\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 53s 7ms/step - loss: 1.3921 - acc: 0.6223 - val_loss: 1.5234 - val_acc: 0.5960\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 1.2873 - acc: 0.6468 - val_loss: 1.4520 - val_acc: 0.6283\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 54s 7ms/step - loss: 1.1873 - acc: 0.6782 - val_loss: 1.4599 - val_acc: 0.6377\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 53s 7ms/step - loss: 1.0948 - acc: 0.7044 - val_loss: 1.4018 - val_acc: 0.6600\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 54s 8ms/step - loss: 1.0050 - acc: 0.7317 - val_loss: 1.3735 - val_acc: 0.6706\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 0.9146 - acc: 0.7595 - val_loss: 1.3717 - val_acc: 0.6728\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Computationally expensive and performed about the same as the Dense network\n",
    "- Validation loss was decreasing and accuracy was continuing to rise, could probably increase by a few more points by just running for more epochs\n",
    "- Started to overfit a bit around epoch 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 602,606\n",
      "Trainable params: 602,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 49s 7ms/step - loss: 2.2044 - acc: 0.3914 - val_loss: 1.8770 - val_acc: 0.4864\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.7607 - acc: 0.5299 - val_loss: 1.7969 - val_acc: 0.5314\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.6245 - acc: 0.5720 - val_loss: 1.6462 - val_acc: 0.5615\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.5351 - acc: 0.5946 - val_loss: 1.5845 - val_acc: 0.5821\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 47s 6ms/step - loss: 1.4626 - acc: 0.6143 - val_loss: 1.5717 - val_acc: 0.5838\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 48s 7ms/step - loss: 1.3946 - acc: 0.6358 - val_loss: 1.5791 - val_acc: 0.6027\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.3174 - acc: 0.6596 - val_loss: 1.5125 - val_acc: 0.6277\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.2382 - acc: 0.6836 - val_loss: 1.4600 - val_acc: 0.6227\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.1561 - acc: 0.6990 - val_loss: 1.4730 - val_acc: 0.6372\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 47s 7ms/step - loss: 1.0724 - acc: 0.7189 - val_loss: 1.3949 - val_acc: 0.6505\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_gru_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Computationally expensive and slightly worse than the Dense network\n",
    "- Validation loss was decreasing and accuracy was continuing to rise, could probably increase by a few more points by just running for more epochs\n",
    "- Started to overfit a bit around epoch 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Dimensional CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 94, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 12, 64)            28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 635,310\n",
      "Trainable params: 635,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jonathan\\Anaconda3\\envs\\msds458\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 4s 494us/step - loss: 1.9897 - acc: 0.4852 - val_loss: 1.6320 - val_acc: 0.5815\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 1s 176us/step - loss: 1.5421 - acc: 0.6058 - val_loss: 1.5099 - val_acc: 0.6394\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 1s 175us/step - loss: 1.3303 - acc: 0.6763 - val_loss: 1.3942 - val_acc: 0.6811\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 1s 179us/step - loss: 1.1304 - acc: 0.7265 - val_loss: 1.3550 - val_acc: 0.6912\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 1s 177us/step - loss: 0.9719 - acc: 0.7635 - val_loss: 1.2935 - val_acc: 0.7028\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 1s 180us/step - loss: 0.8302 - acc: 0.8011 - val_loss: 1.3607 - val_acc: 0.7162\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 1s 177us/step - loss: 0.6990 - acc: 0.8313 - val_loss: 1.3391 - val_acc: 0.7123\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 1s 181us/step - loss: 0.5748 - acc: 0.8637 - val_loss: 1.3395 - val_acc: 0.7012\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 1s 178us/step - loss: 0.4703 - acc: 0.8935 - val_loss: 1.4417 - val_acc: 0.7173\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 1s 178us/step - loss: 0.3849 - acc: 0.9118 - val_loss: 1.4669 - val_acc: 0.7179\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Achieved better results than all other models with less than one second per epoch\n",
    "- Validation loss minimized at around epoch 5\n",
    "- Started overfitting around epoch 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the Conv1D layer with the best-performing RNN so far (LSTM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 94, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 12, 64)            28736     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 668,334\n",
      "Trainable params: 668,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 1.9330 - acc: 0.4907 - val_loss: 1.7330 - val_acc: 0.5454\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.8547 - acc: 0.5157 - val_loss: 1.8262 - val_acc: 0.5303\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.7761 - acc: 0.5495 - val_loss: 1.7590 - val_acc: 0.5370\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.6350 - acc: 0.5930 - val_loss: 1.6729 - val_acc: 0.5771\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.5303 - acc: 0.6166 - val_loss: 1.6462 - val_acc: 0.5715\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.5084 - acc: 0.6195 - val_loss: 1.6109 - val_acc: 0.5954\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.8803 - acc: 0.5230 - val_loss: 1.8761 - val_acc: 0.5314\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.7494 - acc: 0.5677 - val_loss: 1.8954 - val_acc: 0.5175\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.7553 - acc: 0.5708 - val_loss: 1.8627 - val_acc: 0.5465\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 8s 1ms/step - loss: 1.6950 - acc: 0.5829 - val_loss: 1.8607 - val_acc: 0.5320\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Stops improving after around epoch 6\n",
    "- Only slight overfitting starting around epoch 8\n",
    "- Not very computationally-expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected network v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a dropout layer, removing one Dense layer, increasing nodes on first Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 987,502\n",
      "Trainable params: 987,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 3s 408us/step - loss: 2.0944 - acc: 0.4810 - val_loss: 1.6085 - val_acc: 0.6027\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 1s 182us/step - loss: 1.4451 - acc: 0.6434 - val_loss: 1.4232 - val_acc: 0.6594\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 1s 182us/step - loss: 1.0965 - acc: 0.7257 - val_loss: 1.3318 - val_acc: 0.6912\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 1s 181us/step - loss: 0.8307 - acc: 0.7921 - val_loss: 1.3543 - val_acc: 0.6923\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 1s 183us/step - loss: 0.6137 - acc: 0.8458 - val_loss: 1.4435 - val_acc: 0.6956\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 1s 185us/step - loss: 0.4714 - acc: 0.8806 - val_loss: 1.4987 - val_acc: 0.7051\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 1s 188us/step - loss: 0.3755 - acc: 0.9031 - val_loss: 1.6171 - val_acc: 0.6978\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 1s 182us/step - loss: 0.3046 - acc: 0.9265 - val_loss: 1.6936 - val_acc: 0.7034\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 1s 181us/step - loss: 0.2660 - acc: 0.9289 - val_loss: 1.7436 - val_acc: 0.7023\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 1s 189us/step - loss: 0.2309 - acc: 0.9386 - val_loss: 1.8565 - val_acc: 0.6962\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- 0.7 appears to be about our max validation accuracy using only the simple Dense network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (Simple) v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding recurrent dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 100, 32)           3104      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 587,150\n",
      "Trainable params: 587,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(SimpleRNN(32,\n",
    "                    dropout=0.2,\n",
    "                    recurrent_dropout=0.2,\n",
    "                    return_sequences=True))\n",
    "model.add(SimpleRNN(64,\n",
    "                    dropout=0.2,\n",
    "                    recurrent_dropout=0.2))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 50s 7ms/step - loss: 2.6511 - acc: 0.3108 - val_loss: 2.4038 - val_acc: 0.3450\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 50s 7ms/step - loss: 2.3871 - acc: 0.3628 - val_loss: 2.2888 - val_acc: 0.3806\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 49s 7ms/step - loss: 2.2890 - acc: 0.4014 - val_loss: 2.2766 - val_acc: 0.4124\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 2.2228 - acc: 0.4273 - val_loss: 2.1460 - val_acc: 0.4346\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 2.1589 - acc: 0.4523 - val_loss: 2.0936 - val_acc: 0.4585\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 2.0701 - acc: 0.4721 - val_loss: 2.0650 - val_acc: 0.4619\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 2.0031 - acc: 0.4885 - val_loss: 2.0515 - val_acc: 0.4374\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 1.9251 - acc: 0.4930 - val_loss: 2.0691 - val_acc: 0.4380\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 45s 6ms/step - loss: 1.8275 - acc: 0.5221 - val_loss: 2.0520 - val_acc: 0.4474\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 46s 6ms/step - loss: 1.7361 - acc: 0.5429 - val_loss: 2.0360 - val_acc: 0.4441\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_simple_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Not showing much promise with this model.  Training is time-consuming and it is rarely getting even close to the Dense model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (LSTM) v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 610,862\n",
      "Trainable params: 610,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.2,\n",
    "               recurrent_dropout=0.2))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 58s 8ms/step - loss: 2.2902 - acc: 0.4122 - val_loss: 1.9923 - val_acc: 0.4841\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 1.8659 - acc: 0.5048 - val_loss: 1.7412 - val_acc: 0.5498\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.7251 - acc: 0.5499 - val_loss: 1.6971 - val_acc: 0.5526\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 1.6349 - acc: 0.5717 - val_loss: 1.6333 - val_acc: 0.5787\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.5302 - acc: 0.5997 - val_loss: 1.5627 - val_acc: 0.5999\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 1.4365 - acc: 0.6242 - val_loss: 1.5147 - val_acc: 0.6149\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.3513 - acc: 0.6452 - val_loss: 1.4534 - val_acc: 0.6322\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.2521 - acc: 0.6697 - val_loss: 1.4061 - val_acc: 0.6489\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 1.1678 - acc: 0.6906 - val_loss: 1.4007 - val_acc: 0.6566\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.1140 - acc: 0.7081 - val_loss: 1.3614 - val_acc: 0.6756\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Good progress so far on this model, going to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 59s 8ms/step - loss: 1.0562 - acc: 0.7253 - val_loss: 1.3535 - val_acc: 0.6750\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 0.9881 - acc: 0.7446 - val_loss: 1.3286 - val_acc: 0.6867\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 0.9369 - acc: 0.7569 - val_loss: 1.3484 - val_acc: 0.6900\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 0.8896 - acc: 0.7705 - val_loss: 1.3316 - val_acc: 0.6978\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 0.8434 - acc: 0.7825 - val_loss: 1.3290 - val_acc: 0.7040\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 0.7992 - acc: 0.7925 - val_loss: 1.3337 - val_acc: 0.7073\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 56s 8ms/step - loss: 0.7647 - acc: 0.8022 - val_loss: 1.3331 - val_acc: 0.7001\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 58s 8ms/step - loss: 0.7233 - acc: 0.8136 - val_loss: 1.3392 - val_acc: 0.7073\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 58s 8ms/step - loss: 0.6896 - acc: 0.8230 - val_loss: 1.3438 - val_acc: 0.7067\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 57s 8ms/step - loss: 0.6747 - acc: 0.8276 - val_loss: 1.3412 - val_acc: 0.7084\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('rnn_lstm_model.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Starts to overfit significantly during these epochs, although the validation accuracy still got to over 0.7, which makes this the best model so far.\n",
    "- Going to try training one more LSTM model with more agressive dropout rates and stacked LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 643,886\n",
      "Trainable params: 643,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.1,\n",
    "               recurrent_dropout=0.5,\n",
    "               return_sequences=True))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.1,\n",
    "               recurrent_dropout=0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 114s 16ms/step - loss: 2.1939 - acc: 0.4195 - val_loss: 1.8000 - val_acc: 0.5203\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.7913 - acc: 0.5225 - val_loss: 1.7737 - val_acc: 0.5331\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.7304 - acc: 0.5420 - val_loss: 1.7106 - val_acc: 0.5676\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.6460 - acc: 0.5680 - val_loss: 1.6867 - val_acc: 0.5765\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.5863 - acc: 0.5866 - val_loss: 1.6527 - val_acc: 0.5793\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.5107 - acc: 0.6032 - val_loss: 1.5994 - val_acc: 0.5965\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.4453 - acc: 0.6269 - val_loss: 1.5726 - val_acc: 0.6183\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.3883 - acc: 0.6391 - val_loss: 1.5447 - val_acc: 0.6288\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 111s 16ms/step - loss: 1.3355 - acc: 0.6539 - val_loss: 1.5104 - val_acc: 0.6294\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.2829 - acc: 0.6676 - val_loss: 1.4919 - val_acc: 0.6372\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Good progress so far on this model, going to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 115s 16ms/step - loss: 1.2490 - acc: 0.6800 - val_loss: 1.4700 - val_acc: 0.6333\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 110s 15ms/step - loss: 1.1918 - acc: 0.6910 - val_loss: 1.4658 - val_acc: 0.6433\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.1427 - acc: 0.7038 - val_loss: 1.4426 - val_acc: 0.6533\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.0881 - acc: 0.7228 - val_loss: 1.4356 - val_acc: 0.6572\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.0505 - acc: 0.7278 - val_loss: 1.4535 - val_acc: 0.6555\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.0081 - acc: 0.7392 - val_loss: 1.4638 - val_acc: 0.6555\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 113s 16ms/step - loss: 0.9781 - acc: 0.7431 - val_loss: 1.4218 - val_acc: 0.6594\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 0.9366 - acc: 0.7566 - val_loss: 1.4508 - val_acc: 0.6605\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 0.9075 - acc: 0.7642 - val_loss: 1.4592 - val_acc: 0.6689\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 113s 16ms/step - loss: 0.8721 - acc: 0.7775 - val_loss: 1.4956 - val_acc: 0.6617\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('rnn_lstm_model_v2.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Starts to overfit significantly during these epochs.  Model stops improving after around\n",
    "- May want to try one more model with even higher regularization values (run for 20 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 643,886\n",
      "Trainable params: 643,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.5,\n",
    "               recurrent_dropout=0.5,\n",
    "               return_sequences=True))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.5,\n",
    "               recurrent_dropout=0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 117s 16ms/step - loss: 2.2638 - acc: 0.4036 - val_loss: 1.8574 - val_acc: 0.5114\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.8338 - acc: 0.5113 - val_loss: 1.9191 - val_acc: 0.5136\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.7580 - acc: 0.5321 - val_loss: 1.7615 - val_acc: 0.5437\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.7092 - acc: 0.5482 - val_loss: 1.7613 - val_acc: 0.5537\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.6662 - acc: 0.5621 - val_loss: 1.6917 - val_acc: 0.5648\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.6212 - acc: 0.5777 - val_loss: 1.6614 - val_acc: 0.5849\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 111s 16ms/step - loss: 1.5825 - acc: 0.5898 - val_loss: 1.6249 - val_acc: 0.5854\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.5440 - acc: 0.6015 - val_loss: 1.6480 - val_acc: 0.5915\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.5076 - acc: 0.6146 - val_loss: 1.6151 - val_acc: 0.6038\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.4677 - acc: 0.6259 - val_loss: 1.5490 - val_acc: 0.6093\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 116s 16ms/step - loss: 1.4361 - acc: 0.6387 - val_loss: 1.5252 - val_acc: 0.6244\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.3948 - acc: 0.6494 - val_loss: 1.5181 - val_acc: 0.6333\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.3559 - acc: 0.6543 - val_loss: 1.4908 - val_acc: 0.6405\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.3243 - acc: 0.6619 - val_loss: 1.4692 - val_acc: 0.6416\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.2847 - acc: 0.6701 - val_loss: 1.4744 - val_acc: 0.6439\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.2603 - acc: 0.6763 - val_loss: 1.4456 - val_acc: 0.6394\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 111s 15ms/step - loss: 1.2289 - acc: 0.6866 - val_loss: 1.4758 - val_acc: 0.6489\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.2030 - acc: 0.6870 - val_loss: 1.4410 - val_acc: 0.6505\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 114s 16ms/step - loss: 1.1741 - acc: 0.6965 - val_loss: 1.4706 - val_acc: 0.6494\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 124s 17ms/step - loss: 1.1446 - acc: 0.7003 - val_loss: 1.4348 - val_acc: 0.6555\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('rnn_lstm_model_v3.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model_v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Still improving.  Running for an additional 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 119s 17ms/step - loss: 1.1301 - acc: 0.7056 - val_loss: 1.4057 - val_acc: 0.6605\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 125s 17ms/step - loss: 1.1083 - acc: 0.7086 - val_loss: 1.4176 - val_acc: 0.6550\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.0811 - acc: 0.7177 - val_loss: 1.4214 - val_acc: 0.6617\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 113s 16ms/step - loss: 1.0604 - acc: 0.7219 - val_loss: 1.4449 - val_acc: 0.6667\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 116s 16ms/step - loss: 1.0366 - acc: 0.7299 - val_loss: 1.4277 - val_acc: 0.6711\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 114s 16ms/step - loss: 1.0240 - acc: 0.7303 - val_loss: 1.4549 - val_acc: 0.6661\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 1.0090 - acc: 0.7367 - val_loss: 1.4374 - val_acc: 0.6617\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 112s 16ms/step - loss: 0.9819 - acc: 0.7427 - val_loss: 1.4247 - val_acc: 0.6656\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 113s 16ms/step - loss: 0.9653 - acc: 0.7473 - val_loss: 1.4463 - val_acc: 0.6733\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 115s 16ms/step - loss: 0.9656 - acc: 0.7475 - val_loss: 1.4378 - val_acc: 0.6756\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('rnn_lstm_model_v3.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_lstm_model_v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- The validation accuracy is improving very slightly still, but the model is starting to severely overfit and the computational time is getting too large.  Going to use the first version of the improved model moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (GRU) v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 602,606\n",
      "Trainable params: 602,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(GRU(64,\n",
    "              dropout=0.2,\n",
    "              recurrent_dropout=0.2))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 2.2493 - acc: 0.3942 - val_loss: 1.9054 - val_acc: 0.4808\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 1.8086 - acc: 0.5168 - val_loss: 1.7545 - val_acc: 0.5376\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 48s 7ms/step - loss: 1.7019 - acc: 0.5493 - val_loss: 1.7222 - val_acc: 0.5587\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 49s 7ms/step - loss: 1.6391 - acc: 0.5716 - val_loss: 1.6703 - val_acc: 0.5676\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 50s 7ms/step - loss: 1.5918 - acc: 0.5858 - val_loss: 1.6373 - val_acc: 0.5938\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 1.5323 - acc: 0.6008 - val_loss: 1.5991 - val_acc: 0.5838\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 1.4761 - acc: 0.6141 - val_loss: 1.5609 - val_acc: 0.6004\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 1.4154 - acc: 0.6269 - val_loss: 1.5123 - val_acc: 0.6166\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 1.3607 - acc: 0.6402 - val_loss: 1.4897 - val_acc: 0.6177\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 1.3050 - acc: 0.6586 - val_loss: 1.4573 - val_acc: 0.6338\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_gru_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Training well so far.  Going to keep it going..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 55s 8ms/step - loss: 1.2436 - acc: 0.6711 - val_loss: 1.4316 - val_acc: 0.6366\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 1.1971 - acc: 0.6888 - val_loss: 1.3769 - val_acc: 0.6550\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 48s 7ms/step - loss: 1.1388 - acc: 0.7074 - val_loss: 1.3827 - val_acc: 0.6539\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 49s 7ms/step - loss: 1.0921 - acc: 0.7151 - val_loss: 1.3349 - val_acc: 0.6756\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 49s 7ms/step - loss: 1.0402 - acc: 0.7342 - val_loss: 1.3152 - val_acc: 0.6800\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 0.9971 - acc: 0.7467 - val_loss: 1.2968 - val_acc: 0.6873\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 0.9594 - acc: 0.7564 - val_loss: 1.2734 - val_acc: 0.6945\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 52s 7ms/step - loss: 0.9315 - acc: 0.7621 - val_loss: 1.2670 - val_acc: 0.6861\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 53s 7ms/step - loss: 0.9066 - acc: 0.7673 - val_loss: 1.2794 - val_acc: 0.6861\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 51s 7ms/step - loss: 0.8621 - acc: 0.7779 - val_loss: 1.2696 - val_acc: 0.6834\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('rnn_gru_model.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_gru_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Model look ok, but not as effective as the LSTM.  Will use that one moving forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Dimensional CNN v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/15\n",
      "7185/7185 [==============================] - 11s 2ms/step - loss: 2.1115 - acc: 0.4593 - val_loss: 1.6841 - val_acc: 0.5615\n",
      "Epoch 2/15\n",
      "7185/7185 [==============================] - 2s 216us/step - loss: 1.6694 - acc: 0.5726 - val_loss: 1.5914 - val_acc: 0.5915\n",
      "Epoch 3/15\n",
      "7185/7185 [==============================] - 2s 217us/step - loss: 1.5088 - acc: 0.6132 - val_loss: 1.5676 - val_acc: 0.6199\n",
      "Epoch 4/15\n",
      "7185/7185 [==============================] - 2s 216us/step - loss: 1.3651 - acc: 0.6618 - val_loss: 1.4396 - val_acc: 0.6711\n",
      "Epoch 5/15\n",
      "7185/7185 [==============================] - 2s 220us/step - loss: 1.2181 - acc: 0.7037 - val_loss: 1.4245 - val_acc: 0.6767\n",
      "Epoch 6/15\n",
      "7185/7185 [==============================] - 2s 220us/step - loss: 1.1023 - acc: 0.7255 - val_loss: 1.4184 - val_acc: 0.6895\n",
      "Epoch 7/15\n",
      "7185/7185 [==============================] - 2s 217us/step - loss: 1.0053 - acc: 0.7421 - val_loss: 1.4070 - val_acc: 0.6967\n",
      "Epoch 8/15\n",
      "7185/7185 [==============================] - 2s 221us/step - loss: 0.9089 - acc: 0.7617 - val_loss: 1.3866 - val_acc: 0.6989\n",
      "Epoch 9/15\n",
      "7185/7185 [==============================] - 2s 215us/step - loss: 0.8349 - acc: 0.7809 - val_loss: 1.4643 - val_acc: 0.7062\n",
      "Epoch 10/15\n",
      "7185/7185 [==============================] - 2s 216us/step - loss: 0.7544 - acc: 0.7978 - val_loss: 1.5960 - val_acc: 0.7067\n",
      "Epoch 11/15\n",
      "7185/7185 [==============================] - 2s 218us/step - loss: 0.6946 - acc: 0.8199 - val_loss: 1.6174 - val_acc: 0.7117\n",
      "Epoch 12/15\n",
      "7185/7185 [==============================] - 2s 216us/step - loss: 0.6572 - acc: 0.8232 - val_loss: 1.5608 - val_acc: 0.7212\n",
      "Epoch 13/15\n",
      "7185/7185 [==============================] - 2s 217us/step - loss: 0.6021 - acc: 0.8427 - val_loss: 1.5266 - val_acc: 0.7173\n",
      "Epoch 14/15\n",
      "7185/7185 [==============================] - 2s 217us/step - loss: 0.5539 - acc: 0.8476 - val_loss: 1.6334 - val_acc: 0.7229\n",
      "Epoch 15/15\n",
      "7185/7185 [==============================] - 2s 218us/step - loss: 0.5292 - acc: 0.8604 - val_loss: 1.7210 - val_acc: 0.7251\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('1d_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Still incredibly fast training times, although the accuracy is not much better than the non-dropout version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Network v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 94, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 12, 64)            28736     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 668,334\n",
      "Trainable params: 668,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(LSTM(64,\n",
    "               dropout=0.2,\n",
    "               recurrent_dropout=0.2))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 15s 2ms/step - loss: 1.9717 - acc: 0.4814 - val_loss: 1.7859 - val_acc: 0.5314\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.6075 - acc: 0.5685 - val_loss: 1.5449 - val_acc: 0.6016\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 1.5988 - acc: 0.5829 - val_loss: 2.0398 - val_acc: 0.4919\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.7183 - acc: 0.5566 - val_loss: 1.6259 - val_acc: 0.5832\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.4844 - acc: 0.6159 - val_loss: 1.5672 - val_acc: 0.5965\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.3858 - acc: 0.6418 - val_loss: 1.5210 - val_acc: 0.6138\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.3090 - acc: 0.6633 - val_loss: 1.5141 - val_acc: 0.6283\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.2350 - acc: 0.6831 - val_loss: 1.4964 - val_acc: 0.6294\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.1646 - acc: 0.6994 - val_loss: 1.4904 - val_acc: 0.6450\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 1.1062 - acc: 0.7155 - val_loss: 1.4707 - val_acc: 0.6388\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('combo_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Model is starting to overfit, but will continue training for a bit to see where it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 15s 2ms/step - loss: 1.0638 - acc: 0.7340 - val_loss: 1.4204 - val_acc: 0.6583\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 1.0055 - acc: 0.7523 - val_loss: 1.4332 - val_acc: 0.6572\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 9s 1ms/step - loss: 0.9603 - acc: 0.7573 - val_loss: 1.4320 - val_acc: 0.6550\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 0.9184 - acc: 0.7713 - val_loss: 1.4462 - val_acc: 0.6594\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 1.0632 - acc: 0.7346 - val_loss: 1.5013 - val_acc: 0.6516\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 0.9812 - acc: 0.7541 - val_loss: 1.5020 - val_acc: 0.6589\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 0.9299 - acc: 0.7658 - val_loss: 1.5612 - val_acc: 0.6466\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 13s 2ms/step - loss: 0.9005 - acc: 0.7688 - val_loss: 1.5079 - val_acc: 0.6589\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 11s 1ms/step - loss: 0.8666 - acc: 0.7852 - val_loss: 1.5265 - val_acc: 0.6583\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 10s 1ms/step - loss: 0.8340 - acc: 0.7923 - val_loss: 1.5195 - val_acc: 0.6539\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('combo_model.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('combo_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Severe overfitting.  Going to play around with different regularization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_51 (Embedding)     (None, 100, 64)           574848    \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 94, 64)            28736     \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 724,846\n",
      "Trainable params: 724,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "# model.add(MaxPooling1D(5))\n",
    "# model.add(Conv1D(64, 7, activation='relu'))\n",
    "# model.add(LSTM(64,\n",
    "#                dropout=0.5,\n",
    "#                recurrent_dropout=0.5,\n",
    "#                return_sequences=True))\n",
    "model.add(LSTM(128,\n",
    "               dropout=0.5,\n",
    "               recurrent_dropout=0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7185/7185 [==============================] - 98s 14ms/step - loss: 2.1801 - acc: 0.4305 - val_loss: 1.8254 - val_acc: 0.5125\n",
      "Epoch 2/10\n",
      "7185/7185 [==============================] - 75s 10ms/step - loss: 1.8556 - acc: 0.5083 - val_loss: 1.7905 - val_acc: 0.5320\n",
      "Epoch 3/10\n",
      "7185/7185 [==============================] - 75s 10ms/step - loss: 1.7673 - acc: 0.5326 - val_loss: 1.7945 - val_acc: 0.5398\n",
      "Epoch 4/10\n",
      "7185/7185 [==============================] - 74s 10ms/step - loss: 1.6691 - acc: 0.5580 - val_loss: 1.6666 - val_acc: 0.5726\n",
      "Epoch 5/10\n",
      "7185/7185 [==============================] - 73s 10ms/step - loss: 1.5710 - acc: 0.5818 - val_loss: 1.7452 - val_acc: 0.5715\n",
      "Epoch 6/10\n",
      "7185/7185 [==============================] - 75s 10ms/step - loss: 1.4977 - acc: 0.6060 - val_loss: 1.6666 - val_acc: 0.5860\n",
      "Epoch 7/10\n",
      "7185/7185 [==============================] - 74s 10ms/step - loss: 1.4433 - acc: 0.6157 - val_loss: 1.6414 - val_acc: 0.5977\n",
      "Epoch 8/10\n",
      "7185/7185 [==============================] - 73s 10ms/step - loss: 1.3991 - acc: 0.6301 - val_loss: 1.6114 - val_acc: 0.6105\n",
      "Epoch 9/10\n",
      "7185/7185 [==============================] - 74s 10ms/step - loss: 1.3472 - acc: 0.6426 - val_loss: 1.6561 - val_acc: 0.6316\n",
      "Epoch 10/10\n",
      "7185/7185 [==============================] - 73s 10ms/step - loss: 1.3081 - acc: 0.6525 - val_loss: 1.6351 - val_acc: 0.6183\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('combo_model_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 8s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8121196348966495, 0.6923419412819276]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "model.load_weights('1d_cnn_model.h5')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
